{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # Traemos la clase drive, dentro del módulo colab, del paquete google\n",
        "drive.mount('/content/drive') # Establecemos la conexión através del método mount"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxvRM1ZUT2XC",
        "outputId": "908d734a-6847-443d-e08a-23123767396b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oI5g31ipTXTn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aowZcvyYTXTr"
      },
      "outputs": [],
      "source": [
        "# Configuración del modelo y entrenamiento\n",
        "learning_rate = 0.0001\n",
        "batch_size = 32\n",
        "epochs = 200\n",
        "hidden_size = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KiIaJrygTXTs"
      },
      "outputs": [],
      "source": [
        "# Función para cargar y preparar los datos\n",
        "def prepare_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    # Eliminar columnas de tipo 'object' (que generalmente incluyen fechas o strings)\n",
        "    data = data.select_dtypes(exclude=['object'])\n",
        "\n",
        "    X = data.drop(['phishing', 'url'], axis=1, errors='ignore')\n",
        "    y = data['phishing'].values\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
        "    test_dataset = torch.utils.data.TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, test_loader, scaler, X_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gQb0m929TXTt"
      },
      "outputs": [],
      "source": [
        "def create_model(input_size, hidden_size):\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(input_size, hidden_size),  # Capa oculta\n",
        "        nn.Sigmoid(),                          # Función de activación\n",
        "        nn.Linear(hidden_size, 2)           # Capa de salida (dos clases: phishing o no)\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PG_NBdu0TXTt"
      },
      "outputs": [],
      "source": [
        "# Función para entrenar el modelo\n",
        "def train_model(model, train_loader, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "    model.to(device)\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels) # calcula la funcion de costo o perdida entre la predicciones y las etiquetas reales\n",
        "            loss.backward() # calcula los gradientes\n",
        "            optimizer.step() # ajusta los pesos con los gradientes calculados\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_acc)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
        "\n",
        "    return train_losses, train_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9s2U9KPzTXTu"
      },
      "outputs": [],
      "source": [
        "# Función para evaluar el modelo\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'\\nTest Accuracy: {accuracy:.2f}%')\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w6QM6HuMTXTu"
      },
      "outputs": [],
      "source": [
        "# Funciones auxiliares para guardar resultados\n",
        "def save_training_plots(losses, accuracies):\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    save_dir = f'resultados_modelo_{timestamp}'\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(losses)\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.savefig(os.path.join(save_dir, 'training_loss.png'))\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(accuracies)\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.savefig(os.path.join(save_dir, 'training_accuracy.png'))\n",
        "    plt.close()\n",
        "\n",
        "    return save_dir\n",
        "\n",
        "def save_model(model, scaler, save_dir):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'scaler': scaler\n",
        "    }, os.path.join(save_dir, 'model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUnLqyBdTXTv",
        "outputId": "1e16dee2-48e9-44c0-da11-624caa8005ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/200], Loss: 0.6418, Accuracy: 80.30%\n",
            "Epoch [20/200], Loss: 0.5929, Accuracy: 82.88%\n",
            "Epoch [30/200], Loss: 0.5347, Accuracy: 84.07%\n",
            "Epoch [40/200], Loss: 0.4757, Accuracy: 84.92%\n",
            "Epoch [50/200], Loss: 0.4247, Accuracy: 85.63%\n",
            "Epoch [60/200], Loss: 0.3850, Accuracy: 86.19%\n",
            "Epoch [70/200], Loss: 0.3553, Accuracy: 86.69%\n",
            "Epoch [80/200], Loss: 0.3330, Accuracy: 87.08%\n",
            "Epoch [90/200], Loss: 0.3161, Accuracy: 87.45%\n",
            "Epoch [100/200], Loss: 0.3029, Accuracy: 87.76%\n",
            "Epoch [110/200], Loss: 0.2924, Accuracy: 88.08%\n",
            "Epoch [120/200], Loss: 0.2838, Accuracy: 88.33%\n",
            "Epoch [130/200], Loss: 0.2767, Accuracy: 88.59%\n",
            "Epoch [140/200], Loss: 0.2707, Accuracy: 88.83%\n",
            "Epoch [150/200], Loss: 0.2656, Accuracy: 88.98%\n",
            "Epoch [160/200], Loss: 0.2612, Accuracy: 89.16%\n",
            "Epoch [170/200], Loss: 0.2574, Accuracy: 89.30%\n",
            "Epoch [180/200], Loss: 0.2540, Accuracy: 89.41%\n",
            "Epoch [190/200], Loss: 0.2511, Accuracy: 89.55%\n",
            "Epoch [200/200], Loss: 0.2484, Accuracy: 89.69%\n",
            "\n",
            "Test Accuracy: 89.80%\n"
          ]
        }
      ],
      "source": [
        "# Programa principal\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Preparar datos\n",
        "    train_loader, test_loader, scaler, input_size = prepare_data(\"/content/drive/MyDrive/phishing_dataset.csv\")\n",
        "\n",
        "    # Crear modelo\n",
        "    model = create_model(input_size, hidden_size)\n",
        "\n",
        "    # Entrenar modelo\n",
        "    train_losses, train_accuracies = train_model(model, train_loader, device)\n",
        "\n",
        "    # Evaluar modelo\n",
        "    accuracy = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # Guardar resultados\n",
        "    save_dir = save_training_plots(train_losses, train_accuracies)\n",
        "    save_model(model, scaler, save_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}